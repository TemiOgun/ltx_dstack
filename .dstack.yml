# dstack.yaml for Q8 LTX-Video
# Main configuration file for deploying Q8 LTX-Video API with dstack

type: service  # Using "service" as the valid type
name: ltx-video-q8-api  # Changed from project to name

# Define the resources required for the API - reduced VRAM needs with Q8
resources:
  gpu: "RTX 4090"  # Can use smaller GPUs thanks to Q8 optimization (T4 has 16GB VRAM)

spot_policy: "on-demand"

# Define environment variables
env:
  LTX_VIDEO_API_KEY: ${SECRETS.API_KEY}
  LTX_VIDEO_CKPT_PATH: /data/models/ltx_video_q8_model.safetensors
  PORT: 8000
  LOW_VRAM: "true"  # Enable low VRAM mode for Q8
  TRANSFORMER_TYPE: "q8_kernels"  # Specify Q8 kernel usage

# Mount a persistent volume for model storage
volumes:
  - name: ltx-volume
    path: /data

commands:
 # Install system dependencies
  - apt-get update
  - apt-get install -y python3-pip python3-dev ffmpeg git wget curl
  
  # Install Python dependencies
  - pip install torch==2.6.0 torchvision --index-url https://download.pytorch.org/whl/cu126
  - pip install fastapi uvicorn python-multipart pillow imageio numpy pydantic
  - pip install transformers diffusers huggingface_hub
  - pip install ninja  # Required for fast compilation
  
  # Install q8_kernels with submodules
  - git clone https://github.com/KONAKONA666/q8_kernels /app/q8_kernels
  - cd /app/q8_kernels && git submodule init
  - cd /app/q8_kernels && git submodule update
  - cd /app/q8_kernels && python setup.py install
  - cd /app/q8_kernels && pip install .  # for utility
  
  # Clone the Q8 LTX-Video repository
  - git clone https://github.com/TemiOgun/LTX-Video.git /app/LTX-Video
  - cd /app/LTX-Video && python -m pip install -e .\[inference-script\]
  
  # Create directories and download models
  - mkdir -p /data/models/transformer /data/models/vae /data/models/text_encoder /data/models/scheduler
  - mkdir -p /data/outputs /data/static /data/temp_uploads
  - |
    # Install huggingface_hub if not already installed
    pip install huggingface_hub
    
    # Download models
    python -c "from huggingface_hub import snapshot_download; snapshot_download('konakona/ltxvideo_q8', local_dir='/data/models/transformer', local_dir_use_symlinks=False, repo_type='model')"
    python -c "from huggingface_hub import snapshot_download; snapshot_download('Lightricks/LTX-Video', local_dir='/data/models', local_dir_use_symlinks=False, repo_type='model', allow_patterns=['scheduler/*', 'text_encoder/*', 'vae/*'])"
    
    # Create symbolic link
    ln -sf /data/models/transformer/ltx_video_q8_model.safetensors /data/models/ltx_video_q8_model.safetensors
  
  # Run the API server
  - cd /app/LTX-Video && python3 ltx_video_api.py

# Define the port mapping for the API
port: 8000

# Configure replication for high availability
replicas: 1